{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 512 # max number of words going into the model?\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "learning_rate = 0.5e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n_embd = 576  # It's square root should be divisible by n_head\n",
    "sqrt_d = torch.sqrt(torch.tensor(n_embd)).int().item()\n",
    "n_head = 4\n",
    "\n",
    "n_layer = 6\n",
    "dropout = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feebler(nn.Module):\n",
    "    ''' \n",
    "    T: Number of words going into the model\n",
    "    C: Embedding dimension\n",
    "    B: Batch size\n",
    "    \n",
    "    input: B, T, C\n",
    "    output: B, T, sqrt(C)\n",
    "    '''\n",
    "    def __init__(self, sqrt_d):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(sqrt_d, sqrt_d, block_size)\n",
    "        )\n",
    "        self.sqrt_d = sqrt_d\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Data is of shape (b, n, d)\n",
    "        data_reshaped = data.view(batch_size, n_embd, block_size)  # set up data for feebler\n",
    "        data_reshaped = data.view(batch_size, self.sqrt_d, self.sqrt_d, block_size)  # reshape incoming data\n",
    "        product = data_reshaped * self.weights  # multiply data with weights\n",
    "        # perform columnwise sum inside each window\n",
    "        updated_product = torch.sum(product, dim=2, keepdim=False)  # finally we have converted from dxn to sqrt(d)xn\n",
    "        return updated_product.view(batch_size, block_size, self.sqrt_d)\n",
    "    \n",
    "\n",
    "class Booster(nn.Module):\n",
    "    ''' \n",
    "    input: B, T, sqrt(C)\n",
    "    output: B, T, C\n",
    "    '''\n",
    "    def __init__(self, sqrt_d):\n",
    "        super(Booster, self).__init__()\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(sqrt_d, sqrt_d, block_size)\n",
    "        )\n",
    "        self.sqrt_d = sqrt_d\n",
    "\n",
    "    def forward(self, attention_output):\n",
    "        # attention_output is of shape (batch, n, sqrt_d)\n",
    "        # set up data shape for the booster\n",
    "        attention_output = attention_output.view(batch_size, self.sqrt_d, block_size)\n",
    "        attention_output_reshaped = attention_output.view(batch_size, 1, -1) # flatten all rows into one row\n",
    "        attention_output_reshaped = attention_output_reshaped.repeat(1, self.sqrt_d, 1)  # repeat each row sqrt_d times\n",
    "        attention_output_reshaped = attention_output_reshaped.view(batch_size, self.sqrt_d, self.sqrt_d, block_size)\n",
    "        # multiply\n",
    "        revived_output = self.weights * attention_output_reshaped\n",
    "        revived_output = revived_output.view(-1, block_size)\n",
    "        return revived_output.view(batch_size, block_size, n_embd)\n",
    "\n",
    "class QuickHead(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(sqrt_d, head_size, bias=False)\n",
    "        self.query = nn.Linear(sqrt_d, head_size, bias=False)\n",
    "        self.value = nn.Linear(sqrt_d, head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (batch_size, n, sqrt_d)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        v = self.value(x) # (B,T,C)\n",
    "\n",
    "        collective_k = k.sum(1, keepdim=True)\n",
    "        # Broadcast explicitly\n",
    "        collective_k_bc = collective_k.repeat(1, block_size, 1)\n",
    "        # q multiply k\n",
    "        qk = q * collective_k_bc\n",
    "        attention_weights = torch.softmax(qk, dim=1)\n",
    "        collective_v = v.sum(dim=1, keepdim=True)\n",
    "        collective_v_bc = collective_v.repeat(1, block_size, 1)\n",
    "        output = collective_v_bc * attention_weights\n",
    "        return output\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([QuickHead(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(sqrt_d, sqrt_d) # global variable sqrt_d\n",
    "        self.dropout = nn.Dropout(dropout)  # global variable dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, sqrt_d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(sqrt_d, 4 * sqrt_d),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * sqrt_d, sqrt_d),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = sqrt_d // n_head\n",
    "        self.feebler = Feebler(sqrt_d)\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(sqrt_d)\n",
    "        self.ln1 = nn.LayerNorm(sqrt_d)\n",
    "        self.ln2 = nn.LayerNorm(sqrt_d)\n",
    "        self.booster = Booster(sqrt_d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feebler(x)\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        x = self.booster(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 576])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Block(n_embd, n_head)\n",
    "b(torch.rand(batch_size, block_size, n_embd)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100000\n",
    "\n",
    "# super simple quickformer model\n",
    "class Quickformer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, 1)\n",
    "        self.logits_maker = nn.Linear(block_size, 1)\n",
    "        self.classifier = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        x = self.lm_head(x) # (B,T,1)\n",
    "        x = x.squeeze(2) # (B,T)\n",
    "        logits = self.logits_maker(x) # (B,1)\n",
    "        results = self.classifier(logits) # (B, 1)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(results, targets)\n",
    "\n",
    "        return results, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = Quickformer()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand(batch_size, block_size).long().to(device)\n",
    "print(inp.shape)\n",
    "l, ll = model(inp)\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Load IMDb dataset from Hugging Face\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Use a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define a custom PyTorch Dataset\n",
    "class IMDbDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=block_size):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        text = item[\"text\"]\n",
    "        label = item[\"label\"]\n",
    "\n",
    "        # Tokenize and encode the text\n",
    "        inputs = self.tokenizer(\n",
    "            text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"].squeeze()\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label\": torch.tensor(label)}\n",
    "\n",
    "# Create Train dataset (pytorch)\n",
    "imdb_dataset_train = IMDbDataset(dataset[\"train\"], tokenizer)\n",
    "# Create Test dataset (pytorch)\n",
    "imdb_dataset_test = IMDbDataset(dataset[\"test\"], tokenizer)\n",
    "\n",
    "# Create PyTorch DataLoader for train set\n",
    "dataloader_train = DataLoader(imdb_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "# Create PyTorch DataLoader for test set\n",
    "dataloader_test = DataLoader(imdb_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='parquet', dataset_name='imdb', config_name='plain_text', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=33435948, num_examples=25000, shard_lengths=None, dataset_name='imdb'), 'test': SplitInfo(name='test', num_bytes=32653810, num_examples=25000, shard_lengths=None, dataset_name='imdb'), 'unsupervised': SplitInfo(name='unsupervised', num_bytes=67113044, num_examples=50000, shard_lengths=None, dataset_name='imdb')}, download_checksums={'hf://datasets/imdb@e6281661ce1c48d982bc483cf8a173c1bbeb5d31/plain_text/train-00000-of-00001.parquet': {'num_bytes': 20979968, 'checksum': None}, 'hf://datasets/imdb@e6281661ce1c48d982bc483cf8a173c1bbeb5d31/plain_text/test-00000-of-00001.parquet': {'num_bytes': 20470363, 'checksum': None}, 'hf://datasets/imdb@e6281661ce1c48d982bc483cf8a173c1bbeb5d31/plain_text/unsupervised-00000-of-00001.parquet': {'num_bytes': 41996509, 'checksum': None}}, download_size=83446840, post_processing_size=None, dataset_size=133202802, size_in_bytes=216649642)\n",
      "dict_keys(['text', 'label'])\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset info to see the details\n",
    "print(dataset[\"train\"].info)  # shows 0 = neg, 1 = pos\n",
    "\n",
    "print(dataset[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids: torch.Size([16, 512])\n",
      "labels: torch.Size([16, 1])\n",
      "loss: tensor(0.6779, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Testing if my model works well with this dataset\n",
    "# Example of how to iterate through the dataloader\n",
    "for batch in dataloader_train:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"label\"].unsqueeze(1).float().to(device)\n",
    "\n",
    "    print('input ids:', input_ids.shape)\n",
    "    print('labels:', labels.shape)\n",
    "\n",
    "    print('loss:', model(input_ids, labels)[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS DOES NOT WORK\n",
    "# # Testing if my model works well with this dataset\n",
    "# # Example of how to iterate through the dataloader\n",
    "# count = 0\n",
    "# for idx, targets in dataloader_train:\n",
    "#     idx = idx.to(device)\n",
    "#     targets = targets.to(device)\n",
    "#     print('idx:', idx.shape)\n",
    "#     print('targets:', targets.shape)\n",
    "\n",
    "#     print(model(idx, targets)[1])\n",
    "\n",
    "#     count += 1\n",
    "\n",
    "#     if count > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "input_ids = input_ids.to(device)\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5425],\n",
       "         [0.4709],\n",
       "         [0.4675],\n",
       "         [0.5362],\n",
       "         [0.4739],\n",
       "         [0.4905],\n",
       "         [0.5116],\n",
       "         [0.5642],\n",
       "         [0.4918],\n",
       "         [0.5758],\n",
       "         [0.5206],\n",
       "         [0.4978],\n",
       "         [0.4200],\n",
       "         [0.5916],\n",
       "         [0.5114],\n",
       "         [0.5295]], device='cuda:0', grad_fn=<SigmoidBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training:  30%|██▉       | 466/1563 [00:20<00:47, 22.88it/s, Train Loss=0.7]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tuk/Desktop/QuickFormer_Research_Project/text classification/quickformer/components.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m loss_function \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m train_model(model, dataloader_train, dataloader_test, optimizer, loss_function, num_epochs\u001b[39m=\u001b[39mepochs, device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[1;32m/home/tuk/Desktop/QuickFormer_Research_Project/text classification/quickformer/components.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Use tqdm for progress bar\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m train_loader \u001b[39m=\u001b[39m tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Training\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         idx \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/tuk/Desktop/QuickFormer_Research_Project/text classification/quickformer/components.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m label \u001b[39m=\u001b[39m item[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Tokenize and encode the text\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     text, max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m input_ids \u001b[39m=\u001b[39m inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tuk/Desktop/QuickFormer_Research_Project/text%20classification/quickformer/components.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m inputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2806\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2805\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2806\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_one(text\u001b[39m=\u001b[39mtext, text_pair\u001b[39m=\u001b[39mtext_pair, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs)\n\u001b[1;32m   2807\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2808\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2912\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2893\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2894\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2909\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2910\u001b[0m     )\n\u001b[1;32m   2911\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2912\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2913\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2914\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[1;32m   2915\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[1;32m   2916\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2917\u001b[0m         truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   2918\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[1;32m   2919\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[1;32m   2920\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[1;32m   2921\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m   2922\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[1;32m   2923\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m   2924\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m   2925\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m   2926\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m   2927\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m   2928\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[1;32m   2929\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m   2930\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2931\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2985\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2975\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2977\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2978\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2983\u001b[0m )\n\u001b[0;32m-> 2985\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_plus(\n\u001b[1;32m   2986\u001b[0m     text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2987\u001b[0m     text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[1;32m   2988\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[1;32m   2989\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[1;32m   2990\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   2991\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[1;32m   2992\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[1;32m   2993\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[1;32m   2994\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m   2995\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[1;32m   2996\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m   2997\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m   2998\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m   2999\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m   3000\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m   3001\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[1;32m   3002\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m   3003\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   3004\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:544\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_plus\u001b[39m(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    542\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchEncoding:\n\u001b[1;32m    543\u001b[0m     batched_input \u001b[39m=\u001b[39m [(text, text_pair)] \u001b[39mif\u001b[39;00m text_pair \u001b[39melse\u001b[39;00m [text]\n\u001b[0;32m--> 544\u001b[0m     batched_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_encode_plus(\n\u001b[1;32m    545\u001b[0m         batched_input,\n\u001b[1;32m    546\u001b[0m         is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[1;32m    547\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[1;32m    548\u001b[0m         padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[1;32m    549\u001b[0m         truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m    550\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[1;32m    551\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[1;32m    552\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    553\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[1;32m    554\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m    555\u001b[0m         return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m    556\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m    557\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m    558\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m    559\u001b[0m         return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[1;32m    560\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    561\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    562\u001b[0m     )\n\u001b[1;32m    564\u001b[0m     \u001b[39m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[39m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    566\u001b[0m     \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:520\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39mfor\u001b[39;00m input_ids \u001b[39min\u001b[39;00m sanitized_tokens[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    519\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 520\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type\u001b[39m=\u001b[39mreturn_tensors)\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:223\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    219\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> 223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39mprepend_batch_axis)\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:748\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    745\u001b[0m     value \u001b[39m=\u001b[39m [value]\n\u001b[1;32m    747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 748\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[1;32m    750\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/anaconda3/envs/SyedHamza/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:720\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(value[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(value))\n\u001b[0;32m--> 720\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, loss_function, num_epochs=10, device='cuda'):\n",
    "    model.to(device)  # Move the model to the specified device (GPU or CPU)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Use tqdm for progress bar\n",
    "        train_loader = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}, Training')\n",
    "\n",
    "        for batch in train_loader:\n",
    "            try:\n",
    "                idx = batch[\"input_ids\"]\n",
    "                targets = batch[\"label\"].unsqueeze(1).float()\n",
    "                idx, targets = idx.to(device), targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                results, loss = model(idx)\n",
    "                loss = loss_function(results, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * len(idx)\n",
    "                total_samples += len(idx)\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                train_loader.set_postfix({'Train Loss': total_loss / total_samples})\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        average_train_loss = total_loss / total_samples\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Use tqdm for progress bar\n",
    "            test_loader = tqdm(test_loader, desc=f'Epoch {epoch + 1}/{num_epochs}, Validation')\n",
    "\n",
    "            for batch in test_loader:\n",
    "                try:\n",
    "                    idx = batch[\"input_ids\"]\n",
    "                    targets = batch[\"label\"].unsqueeze(1).float()\n",
    "                    idx, targets = idx.to(device), targets.to(device)\n",
    "\n",
    "                    results, loss = model(idx)\n",
    "                    loss = loss_function(results, targets)\n",
    "\n",
    "                    total_loss += loss.item() * len(idx)\n",
    "                    total_samples += len(idx)\n",
    "\n",
    "                    # Update tqdm progress bar\n",
    "                    test_loader.set_postfix({'Test Loss': total_loss / total_samples})\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        average_test_loss = total_loss / total_samples\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {average_train_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n",
    "\n",
    "    print('Training complete!')\n",
    "\n",
    "model = Quickformer()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "train_model(model, dataloader_train, dataloader_test, optimizer, loss_function, num_epochs=epochs, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Accuracy:  94%|█████████▍| 1475/1563 [00:32<00:01, 46.75it/s, Accuracy=0.5]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Accuracy:  96%|█████████▌| 1495/1563 [00:32<00:01, 41.83it/s, Accuracy=0.5]"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, data_loader, device='cuda'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_loader = tqdm(data_loader, desc='Calculating Accuracy')\n",
    "        for batch in data_loader:\n",
    "            try:\n",
    "                idx = batch[\"input_ids\"]\n",
    "                targets = batch[\"label\"].unsqueeze(1).float()\n",
    "                idx, targets = idx.to(device), targets.to(device)\n",
    "\n",
    "                predictions, _ = model(idx)\n",
    "                predictions = torch.round(predictions)\n",
    "\n",
    "                correct += (predictions == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "                data_loader.set_postfix({'Accuracy': correct / total})\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Usage:\n",
    "train_accuracy = calculate_accuracy(model, dataloader_train)\n",
    "test_accuracy = calculate_accuracy(model, dataloader_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SyedHamza",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
