{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA4A3Az6obfO"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2e76qcRCobfP"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# import os\n",
        "# os.environ[\"CUDA_DIR\"] = \"/home/tuk/anaconda3/pkgs/cuda-nvcc-11.6.124-hbba6d2d_0/nvvm\"\n",
        "# !echo ${CUDA_DIR}\\\n",
        "\n",
        "# print(tf.sysconfig.get_build_info() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrZrEYICobfQ",
        "outputId": "3dd343fd-8043-40ab-fb67-c476ad0e79b9"
      },
      "outputs": [],
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "# !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "# !pip install protobuf~=3.20.3\n",
        "# !pip install -q tensorflow_datasets\n",
        "# !pip install -q -U tensorflow-text tensorflow\n",
        "\n",
        "# !pip install transformers\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z8D_-yqobfQ",
        "outputId": "71dd948b-3aa8-4847-d5d4-319cde8319c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tuk/anaconda3/envs/trans/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:33:59.127021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-25 11:33:59.127050: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-25 11:33:59.127867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-25 11:33:59.132693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-25 11:33:59.891419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text\n",
        "\n",
        "import transformers\n",
        "import datasets\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKgXqJvMobfQ"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "1e2fa0ff8d9742508d05c9910654551e",
            "a1c05936d6374066bab9be98bd0adbe8",
            "551851c669c84fe09c82dd98bc6dbf01",
            "1504f8fe687e4fecaf7134fc41f5cbbb",
            "c432ca86db394831a06381ba5131a154",
            "c83302272e864d1dabf1309588bbd3de",
            "fb81c4ea319449c494eab9a5bb82adaa",
            "63a2e7b63ecc44c989d9eea886f1d612",
            "d2ee4bad6ad3404bb18c75d20003ed37",
            "c258bf997cb042c6b275f84c01b355d6",
            "5a2c40b518f4482d8a81be32de548850",
            "56b1c227edfc4ea2b8b4ecf27a355e96",
            "176617868e13453393f6e25220450130",
            "39fea0018eaa4110b2ab96d300e9f7d4",
            "4fb221bf6a5f4f3f8768f9de79a31513",
            "33e76f7907b64cc8a9dba236b94330bf",
            "261b676b5c3947d8be328322f29fc34b",
            "0fe060f155f94172aa9dfb56d84a32a7",
            "46a60f76da394994b50af9b81c3f2834",
            "7c6be6fd17a64322a6a3d28bb547de13",
            "bc3898089d7d437d9cca75c43ae0e36f",
            "baaf6373c2f34eb1983dc5dcb4a03728",
            "2917f9ef0bc84fd8b1889ed3f7d2ca5a",
            "3392047892054d5893b3c6f5fd44c8de",
            "2349d26748a443f7956c1c614b732544",
            "75b7730f4ced4d9d8ce696b2e494fddc",
            "911b832e2351425f9bc7acc6dc04c4fe",
            "26a9d177f540445396617d6e4dee290e",
            "561ab8a97577469c8932ca86cd4f157b",
            "9586d1c2a9a34baea77dd043ac9a0409",
            "e4a6ef913325496385c81f87676de5b3",
            "12f5d21a55084a1eb82fc10a630f511f",
            "2ecb77fbda9149e886040a4a4b71f15c",
            "4596c827b1c54c6db71547a2349a0189",
            "36cf659c026f4a949422af3738711f0c",
            "bf9d5ba948a24acd8b6a3f6961969807",
            "170308f08d8d41f8953bdfea1b0186bd",
            "d187481bbd584dba8d868dc95299a7aa",
            "97cc923d5cff4892a25e6c85d2379dd8",
            "e5a5e30d376340c1b529bec2eced3aef",
            "95d512ae32164dd3a0014a1ff850b3f1",
            "72fb6934a8b34071a737256b0c751ade",
            "c5cac31d8d3e4de782cea6967aaf9413",
            "9c1bb89cd526494891b09755281d76ef",
            "ab4ccf5bbaea48b2bcac1475a2e9f3b2",
            "be1202359bb849d8a9a1ded79213c94e",
            "24d5a44a8169446183dfed66fa2a5e34",
            "310248f70a844312af4b01d8bf989910",
            "e2bee257450a46eb9b2775142bc5d073",
            "14990ee7be254c2fbb1a99a8f3239d83",
            "9fb1066f2ade48efa6f1937760c54eba",
            "406fa15cd71f43f8b22f0edc2e6751ab",
            "72f22ff4856f4bbcabd60dfe4e7af8d9",
            "47935958a0c64d7aa9720bdf5730c52d",
            "c28ab0a4cb7846fea2e64f9cd19bd906"
          ]
        },
        "id": "-JghimPqobfR",
        "outputId": "2ac27bb6-101a-40e1-99a4-eaffeaff32e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tuk/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builders/huggingface_dataset_builder.py:160: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
            "  hf_names = hf_datasets.list_datasets()\n",
            "2024-01-25 11:34:47.459143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.490137: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.490255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.491153: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.491284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.491365: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.536157: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.536296: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.536460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-25 11:34:47.536538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21659 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "examples, metadata = tfds.load('huggingface:opus_books/en-fr',\n",
        "                               with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1dXeN0gobfR",
        "outputId": "4eae9f15-1019-46fa-ddcc-13ededd31929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_PrefetchDataset element_spec={'id': TensorSpec(shape=(), dtype=tf.string, name=None), 'translation': {'en': TensorSpec(shape=(), dtype=tf.string, name=None), 'fr': TensorSpec(shape=(), dtype=tf.string, name=None)}}>\n"
          ]
        }
      ],
      "source": [
        "examples = examples['train']\n",
        "print(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MbR10B3obfR"
      },
      "source": [
        "## Make train test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPVdi641obfR",
        "outputId": "67584389-3bd2-4193-fda4-e81dc8cc55ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101668 127085\n"
          ]
        }
      ],
      "source": [
        "# Get the total number of examples\n",
        "total_examples = metadata.splits['train'].num_examples\n",
        "\n",
        "# Define the split ratios (e.g., 80% train, 20% test)\n",
        "train_ratio = 0.8\n",
        "test_ratio = 1.0 - train_ratio\n",
        "\n",
        "# Calculate the number of examples for each split\n",
        "train_size = int(train_ratio * total_examples)\n",
        "print(train_size, total_examples)\n",
        "\n",
        "# Split the dataset into train and test dictionaries\n",
        "train_examples = list(examples)[:train_size]\n",
        "test_examples = list(examples)[train_size:]\n",
        "\n",
        "# # HARD CODING\n",
        "# # Split the dataset into train and test dictionaries\n",
        "# train_examples = list(examples)[:10000]\n",
        "# test_examples = list(examples)[10000:13000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrLqirLYobfR",
        "outputId": "c4352c3e-a26d-4d5b-b05f-27c68c4dfe10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101668\n",
            "25417\n"
          ]
        }
      ],
      "source": [
        "# Print lengths\n",
        "print(len(train_examples))\n",
        "print(len(test_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR-eifW2obfR"
      },
      "source": [
        "## Process dataset for training the tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PHNNzjGDobfR"
      },
      "outputs": [],
      "source": [
        "formatted_train_examples = []  # list of tuples\n",
        "formatted_test_examples = []  # list of tuples\n",
        "for record in train_examples:\n",
        "    formatted_train_examples.append(\n",
        "        (record['translation']['fr'].numpy(), record['translation']['en'].numpy()))\n",
        "\n",
        "for record in test_examples:\n",
        "    formatted_test_examples.append(\n",
        "        (record['translation']['fr'].numpy(), record['translation']['en'].numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t24DLwssobfS"
      },
      "outputs": [],
      "source": [
        "# Separate the pairs into two lists\n",
        "fr_train_list, en_train_list = zip(*formatted_train_examples)\n",
        "fr_test_list, en_test_list = zip(*formatted_test_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ihbooxB4obfS"
      },
      "outputs": [],
      "source": [
        "# Create TensorFlow tensors from the values\n",
        "fr_train_tensor = tf.stack(fr_train_list)\n",
        "en_train_tensor = tf.stack(en_train_list)\n",
        "fr_test_tensor = tf.stack(fr_test_list)\n",
        "en_test_tensor = tf.stack(en_test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XuVOx0SGobfS"
      },
      "outputs": [],
      "source": [
        "# Create a dataset from the tensors\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((fr_train_tensor, en_train_tensor))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((fr_test_tensor, en_test_tensor))\n",
        "\n",
        "# Prefetch the datasets for better performance\n",
        "train_examples = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_examples = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7__ikf2kobfS",
        "outputId": "ef36355a-9592-4cd8-89d3-03006dedf7b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Examples in French:\n",
            "Le grand Meaulnes\n",
            "Alain-Fournier\n",
            "PREMIÈRE PARTIE\n",
            "\n",
            "> Examples in English:\n",
            "The Wanderer\n",
            "Alain-Fournier\n",
            "First Part\n"
          ]
        }
      ],
      "source": [
        "for fr_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples in French:')\n",
        "  for fr in fr_examples.numpy():\n",
        "    print(fr.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Examples in English:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzeOXVH3obfS"
      },
      "source": [
        "## Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LPw4NJmQobfS"
      },
      "outputs": [],
      "source": [
        "# Convert tensors to numpy arrays\n",
        "fr_train_array = fr_train_tensor.numpy()\n",
        "en_train_array = en_train_tensor.numpy()\n",
        "fr_test_array = fr_test_tensor.numpy()\n",
        "en_test_array = en_test_tensor.numpy()\n",
        "\n",
        "# Convert numpy arrays to lists of strings\n",
        "fr_train_texts = ['START ' + fr.decode('utf-8') + ' END' for fr in fr_train_array]\n",
        "en_train_texts = ['START ' + en.decode('utf-8') + ' END' for en in en_train_array]\n",
        "fr_test_texts = ['START ' + fr.decode('utf-8') + ' END' for fr in fr_test_array]\n",
        "en_test_texts = ['START ' + en.decode('utf-8') + ' END' for en in en_test_array]\n",
        "\n",
        "# Tokenizer for English\n",
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "en_tokenizer.fit_on_texts(en_train_texts)\n",
        "\n",
        "# Tokenizer for French\n",
        "fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "fr_tokenizer.fit_on_texts(fr_train_texts)\n",
        "\n",
        "# Tokenize and pad the sequences\n",
        "en_train_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    en_tokenizer.texts_to_sequences(en_train_texts),\n",
        "    padding='post'\n",
        ")\n",
        "fr_train_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    fr_tokenizer.texts_to_sequences(fr_train_texts),\n",
        "    padding='post'\n",
        ")\n",
        "en_test_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    en_tokenizer.texts_to_sequences(en_test_texts),\n",
        "    padding='post'\n",
        ")\n",
        "fr_test_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    fr_tokenizer.texts_to_sequences(fr_test_texts),\n",
        "    padding='post'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtClhSeTobfT",
        "outputId": "9e791a7a-55de-42e8-bdca-0a33a50a9774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English vocabulary size: 126355\n",
            "French vocabulary size: 142530\n"
          ]
        }
      ],
      "source": [
        "en_vocab_size = vocab_size = len(en_tokenizer.word_index) + 1\n",
        "fr_vocab_size = vocab_size = len(fr_tokenizer.word_index) + 1\n",
        "\n",
        "print('English vocabulary size:', en_vocab_size)\n",
        "print('French vocabulary size:', fr_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_9OhZP7obfT",
        "outputId": "2e522c5c-218a-4780-dafe-3f5d74d3700c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    3,     1, 18209,     2,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0], dtype=int32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en = en_train_sequences[0]\n",
        "fr = fr_train_sequences[0]\n",
        "en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tr1M8BbobfT",
        "outputId": "877345c2-e14c-4203-cd21-ef6187cf06fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized English training sequences:\n",
            "[    3     1 18209     2     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n",
            "\n",
            "Tokenized French training sequences:\n",
            "[  2   6 132 795   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0]\n",
            "\n",
            "Tokenized English test sequences:\n",
            "[    3    70    44    57   460    16    94    52   156   386     5   804\n",
            "   128     5    14     6     1  3599 26501    16     7  2680  2764     9\n",
            "    32   264     4     1  5180     2     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0]\n",
            "\n",
            "Tokenized French test sequences:\n",
            "[     2    289     32     68  11404     39     98    361     15  26803\n",
            "     32   1015     25      5   5414      4 115361      5  16214  45877\n",
            "    116   7311   4108     19     45    316      3   1989      1      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0]\n"
          ]
        }
      ],
      "source": [
        "# Print the tokenized sequences\n",
        "print(\"Tokenized English training sequences:\")\n",
        "for seq in en_train_sequences:\n",
        "    print(seq)\n",
        "    break\n",
        "\n",
        "print(\"\\nTokenized French training sequences:\")\n",
        "for seq in fr_train_sequences:\n",
        "    print(seq)\n",
        "    break\n",
        "\n",
        "print(\"\\nTokenized English test sequences:\")\n",
        "for seq in en_test_sequences:\n",
        "    print(seq)\n",
        "    break\n",
        "\n",
        "print(\"\\nTokenized French test sequences:\")\n",
        "for seq in fr_test_sequences:\n",
        "    print(seq)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mmr6VTobfT",
        "outputId": "c2be54d6-12f3-42b4-8627-a12ca5a52879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example Input (French): (32, 326)\n",
            "Example Input (English - Input): (32, 373)\n",
            "Example Label (English - Output): (32, 373)\n"
          ]
        }
      ],
      "source": [
        "# Set batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create TensorFlow datasets for training and testing with batching\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((fr_train_sequences, en_train_sequences[:, :-1]), en_train_sequences[:, 1:]))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(fr_train_sequences)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(((fr_test_sequences, en_test_sequences[:, :-1]), en_test_sequences[:, 1:]))\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Print the first example from the training dataset\n",
        "for (fr, en), en_label in train_dataset.take(1):\n",
        "    print(\"Example Input (French):\", fr.shape)\n",
        "    print(\"Example Input (English - Input):\", en.shape)\n",
        "    print(\"Example Label (English - Output):\", en_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHZ5SzQpobfT"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEW6ve9JobfT",
        "outputId": "0b7d519d-aed6-433d-b40e-d98593a5828d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([4, 2])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "positional_encoding(4, 2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "x9p9WmkOobfU"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]  # No of words\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    # x *= tf.pow(self.d_model, tf.constant(0.5, dtype=tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CygXk9QnobfU"
      },
      "outputs": [],
      "source": [
        "embed_fr = PositionalEmbedding(vocab_size=fr_vocab_size, d_model=512)\n",
        "embed_en = PositionalEmbedding(vocab_size=en_vocab_size, d_model=512)\n",
        "\n",
        "fr = tf.stack(fr_train_sequences[0:2])\n",
        "en = tf.stack(en_train_sequences[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FwxuaxvobfU",
        "outputId": "114e40db-67c7-409f-c65b-0433117fae2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "French input shape: (2, 326)\n",
            "(2, 326, 512)\n",
            "English input shape: (2, 374)\n",
            "(2, 374, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:21.487980: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.489003: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
            "2024-01-25 11:35:21.489017: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
            "2024-01-25 11:35:21.489056: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        }
      ],
      "source": [
        "print('French input shape:', fr.shape)\n",
        "fr_emb = embed_fr(fr)\n",
        "print(fr_emb.shape)\n",
        "\n",
        "print('English input shape:', en.shape)\n",
        "en_emb = embed_en(en)\n",
        "print(en_emb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLh928lbobfU",
        "outputId": "5efc5a1b-8be1-4402-839a-85e91e297d55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 374), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False],\n",
              "       [ True,  True,  True, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False]])>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_emb._keras_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kk4r-sWuobfU"
      },
      "outputs": [],
      "source": [
        "# MultiHeadAttention Layer\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, key_dim, dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        assert key_dim % num_heads == 0\n",
        "\n",
        "        self.depth = key_dim // num_heads\n",
        "\n",
        "        self.query_dense = tf.keras.layers.Dense(key_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(key_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(key_dim)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(key_dim)\n",
        "\n",
        "    def _masked_softmax(self, attention_scores, attention_mask):\n",
        "        \"\"\"Computes a softmax with explicit padding.\n",
        "\n",
        "        Args:\n",
        "            attention_scores: A tensor with shape [batch_size, num_heads,\n",
        "                query_seq_length, memory_seq_length]\n",
        "            attention_mask: A tensor with shape [batch_size, 1, query_seq_length,\n",
        "                memory_seq_length], the original attention mask.\n",
        "\n",
        "        Returns:\n",
        "            attention_probs: A tensor with shape [batch_size, num_heads,\n",
        "                query_seq_length, memory_seq_length], the new attention mask.\n",
        "        \"\"\"\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        # `attention_scores` = [B, N, T, S]\n",
        "        attention_mask = tf.expand_dims(\n",
        "            attention_mask, axis=1\n",
        "        )\n",
        "\n",
        "        # Add a large negative value to masked positions to make their attention scores close to zero\n",
        "        attention_scores = attention_scores + (1.0 - tf.cast(attention_mask, tf.float32)) * -1e9\n",
        "\n",
        "        # Calculate softmax along the last dimension (memory_seq_length)\n",
        "        attention_probs = tf.nn.softmax(attention_scores, axis=-1)\n",
        "\n",
        "        return attention_probs\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(inputs, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
        "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "        attention_weights = self._masked_softmax(scaled_attention_logits, mask)\n",
        "        output = tf.matmul(attention_weights, v)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "    def call(self, query, key, value, use_causal_mask=False):\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        mask = self._compute_attention_mask(query, value, key, use_causal_mask=use_causal_mask)\n",
        "\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = self.scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.key_dim))\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "    def _compute_attention_mask(\n",
        "        self, query, value, key=None, attention_mask=None, use_causal_mask=False\n",
        "    ):\n",
        "        \"\"\" Computes the attention mask, using the Keras masks of the inputs. \"\"\"\n",
        "        query_mask = getattr(query, \"_keras_mask\", None)\n",
        "        value_mask = getattr(value, \"_keras_mask\", None)\n",
        "        key_mask = getattr(key, \"_keras_mask\", None)\n",
        "        auto_mask = None\n",
        "        if query_mask is not None:\n",
        "            query_mask = tf.cast(query_mask, tf.bool)  # defensive casting\n",
        "            # B = batch size, T = max query length\n",
        "            auto_mask = query_mask[:, :, tf.newaxis]  # shape is [B, T, 1]\n",
        "        if value_mask is not None:\n",
        "            value_mask = tf.cast(value_mask, tf.bool)  # defensive casting\n",
        "            # B = batch size, S == max value length\n",
        "            mask = value_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if key_mask is not None:\n",
        "            key_mask = tf.cast(key_mask, tf.bool)  # defensive casting\n",
        "            # B == batch size, S == max key length == max value length\n",
        "            mask = key_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if use_causal_mask:\n",
        "            # the shape of the causal mask is [1, T, S]\n",
        "            mask = self._compute_causal_mask(query, value)\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if auto_mask is not None:\n",
        "            # merge attention_mask & automatic mask, to shape [B, T, S]\n",
        "            attention_mask = (\n",
        "                auto_mask\n",
        "                if attention_mask is None\n",
        "                else tf.cast(attention_mask, bool) & auto_mask\n",
        "            )\n",
        "        return attention_mask\n",
        "\n",
        "    def _compute_causal_mask(self, query, value=None):\n",
        "        \"\"\" Computes the causal attention mask. \"\"\"\n",
        "\n",
        "        q_seq_length = tf.shape(query)[1]\n",
        "        v_seq_length = q_seq_length if value is None else tf.shape(value)[1]\n",
        "        return tf.linalg.band_part(  # creates a lower triangular matrix\n",
        "            tf.ones((1, q_seq_length, v_seq_length), tf.bool), -1, 0\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TaHo3VmsobfV"
      },
      "outputs": [],
      "source": [
        "# All its child layers need num_heads and key_dim(or dmodel) for initialization\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4jHz6kVZobfV"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dSHtrYuobfV",
        "outputId": "0558fb87-70c0-4f6e-dd87-c7d4e8e3f2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 326, 512)\n",
            "(2, 374, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:21.633268: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.633349: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.633391: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.633626: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.634162: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.634436: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.634650: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.635086: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.635276: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.635542: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.636065: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.636093: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.636106: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.636213: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:21.636779: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:21.637793: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:21.836600: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
          ]
        }
      ],
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(fr_emb.shape)\n",
        "print(en_emb.shape)\n",
        "print(sample_ca(en_emb, fr_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-XIE4HJbobfW"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX6NEPJJobfW",
        "outputId": "c697142d-e0b9-4076-dc94-4f9b112e4f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 326, 512)\n",
            "(2, 326, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(fr_emb.shape)\n",
        "print(sample_gsa(fr_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VKBgvHnhobfW"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPLw331oobfW",
        "outputId": "bbb4dfc0-099f-41b6-85d5-6240fabb3240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374, 512)\n",
            "(2, 374, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "print(en_emb.shape)\n",
        "print(sample_csa(en_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1fcoWxdobfW",
        "outputId": "cd1a1fa0-0370-41fe-b5f3-2b7a4abcb6b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00062036514"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out1 = sample_csa(embed_en(en[:, :3]))\n",
        "out2 = sample_csa(embed_en(en))[:, :3]\n",
        "\n",
        "tf.reduce_max(abs(out1 - out2)).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sTZVFb2RobfW"
      },
      "outputs": [],
      "source": [
        "# This layer needs dmodel and dff for initialization\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuYuCUktobfW",
        "outputId": "906d39c1-234b-4f2d-c69c-2613fcccf085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374, 512)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:22.068679: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:22.069929: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        }
      ],
      "source": [
        "sample_ffn = FeedForward(512, 2048)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_ffn(en_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Q7lWKLObobfX"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7nKhDXwobfX",
        "outputId": "78d134a1-c9e8-4462-8a6e-baa4a965a03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 326, 512)\n",
            "(2, 326, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_enc_layer = EncoderLayer(d_model=512, num_heads=4, dff=2048, dropout_rate=0.1)\n",
        "\n",
        "print(fr_emb.shape)\n",
        "print(sample_enc_layer(fr_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "l5kpTCPcobfX"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0Be4h7pobfX",
        "outputId": "8a5f13d1-d87f-405c-ca5d-d0a7a33e8270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 326)\n",
            "(2, 326, 512)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder.\n",
        "sample_encoder = Encoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=fr_vocab_size)\n",
        "\n",
        "sample_encoder_output = sample_encoder(fr, training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(fr.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jFx5XtwzobfX"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbVMwWY8obfX",
        "outputId": "7c3ed4c7-108a-4571-b3c6-2eaef35f8c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374, 512)\n"
          ]
        }
      ],
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(\n",
        "    x=en_emb, context=fr_emb\n",
        ")\n",
        "\n",
        "print(sample_decoder_layer_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8CPBX0G7obfY"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL3BdVm1obfY",
        "outputId": "43f850ba-910a-4972-f387-afeda6cb037b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374)\n",
            "(2, 326, 512)\n",
            "(2, 374, 512)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the decoder.\n",
        "sample_decoder = Decoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=en_vocab_size)\n",
        "\n",
        "output = sample_decoder(\n",
        "    x=en,\n",
        "    context=fr_emb)\n",
        "\n",
        "# Print the shapes.\n",
        "print(en.shape)\n",
        "print(fr_emb.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "l2w_OR8CobfY"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "B_iC09cOobfY"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 256\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uspQkoCqobfY"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=fr_vocab_size,\n",
        "    target_vocab_size=en_vocab_size,\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8KaLfdDobfY",
        "outputId": "94ade62a-cbfd-45af-9a39-b4241d682f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 374)\n",
            "(2, 326)\n",
            "(2, 374, 126355)\n"
          ]
        }
      ],
      "source": [
        "output = transformer((fr, en))\n",
        "\n",
        "print(en.shape)\n",
        "print(fr.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFLl3VOPobfY",
        "outputId": "ed22c51f-5941-42e2-ccf1-b6250264c1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 8, 374, 326)\n"
          ]
        }
      ],
      "source": [
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h7HrdiZobfZ",
        "outputId": "475d09d4-e4b8-4ac8-dbe8-e1e1200cc467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  38596096  \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  35510016  \n",
            "                                                                 \n",
            " dense_158 (Dense)           multiple                  32473235  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 106579347 (406.57 MB)\n",
            "Trainable params: 106579347 (406.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W91fHiB0obfZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZqwT9qhGobfZ"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "y3Y2P2QIobfZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:23.644524: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.645844: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.725970: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.726056: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.726608: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.726822: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.727325: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.727660: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.727901: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.727954: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.728890: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.728904: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.728917: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.729844: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:23.730001: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.730016: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.730029: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:23.731028: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        }
      ],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "JJdJDQriobfZ",
        "outputId": "caa74ee5-bfcc-4398-9f11-9233fb1552f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6SxrtMh-obfZ"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none'\n",
        "  )\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = label!=0\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "\n",
        "  mask = label!=0\n",
        "  match = label==pred\n",
        "  match  = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MfNMho-obfZ",
        "outputId": "8eddce4f-ef93-40c8-b4f3-4ab6495642c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BUVa51U9obfa"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V4ni6C-obfa",
        "outputId": "694733e3-9341-430b-c544-e0823bbea923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:42.500000: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.501477: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.636966: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.640095: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.640318: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.643728: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.647610: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.648587: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.652515: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.654996: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.655935: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.656000: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.656252: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.659108: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.666863: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.668670: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.670792: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.672309: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.672679: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.672971: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.673607: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.674672: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.675049: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.676205: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.677622: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.679554: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.681036: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.686401: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.687207: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.687874: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.688042: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.688312: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.688460: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.692024: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:42.692455: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.693565: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.697673: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:42.697988: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2024-01-25 11:35:43.437737: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f797c1b5150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-01-25 11:35:43.437770: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
            "2024-01-25 11:35:43.441757: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-01-25 11:35:43.474026: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1706153743.489564   90568 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2024-01-25 11:35:43.534848: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:43.639451: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:43.786562: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:43.834296: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:43.884576: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:44.070740: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "2024-01-25 11:35:48.722934: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1/3178 [..............................] - ETA: 23:45:14 - loss: 11.7465 - masked_accuracy: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-25 11:35:51.042658: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3178/3178 [==============================] - 2078s 646ms/step - loss: 7.0842 - masked_accuracy: 0.1247 - val_loss: 5.9774 - val_masked_accuracy: 0.1912\n",
            "Epoch 2/100\n",
            "3178/3178 [==============================] - 2038s 641ms/step - loss: 5.9765 - masked_accuracy: 0.1851 - val_loss: 5.7046 - val_masked_accuracy: 0.2110\n",
            "Epoch 3/100\n",
            "1854/3178 [================>.............] - ETA: 12:50 - loss: 5.6836 - masked_accuracy: 0.2053"
          ]
        }
      ],
      "source": [
        "transformer.fit(train_dataset,\n",
        "                epochs=100,\n",
        "                validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPy298u7obfa"
      },
      "source": [
        "## Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLPkWeLoobfa"
      },
      "outputs": [],
      "source": [
        "def print_translation(sentence, text, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {text}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZF-PSWTobfa",
        "outputId": "4958d51d-e484-4247-b7c2-49dd4dd3020d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token for 'Start': tf.Tensor(3, shape=(), dtype=int64)\n",
            "Token for 'End': tf.Tensor(2, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# Get the token for 'Start'\n",
        "start_token = en_tokenizer.word_index['start']\n",
        "start_token = tf.constant(start_token, dtype=tf.int64)\n",
        "\n",
        "# Get the token for 'End'\n",
        "end_token = en_tokenizer.word_index['end']\n",
        "end_token = tf.constant(end_token, dtype=tf.int64)\n",
        "\n",
        "print(\"Token for 'Start':\", start_token)\n",
        "print(\"Token for 'End':\", end_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM96ALuEobfa"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, en_tokenizer, fr_tokenizer, transformer):\n",
        "    self.en_tokenizer = en_tokenizer\n",
        "    self.fr_tokenizer = fr_tokenizer\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=206):\n",
        "\n",
        "    encoder_input = sentence  # (1, 11)\n",
        "    start = start_token  # shape=(1,)\n",
        "    end = end_token  # shape=(1,)\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())  # (1, X)\n",
        "      output = tf.expand_dims(output, 0)\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0][0])  # Writing a tensor of shape 1\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    # text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
        "\n",
        "    # tokens = tokenizers.en.lookup(output)[0]\n",
        "    text = en_tokenizer.sequences_to_texts([output.numpy()])[0]\n",
        "    # text = text.split(' ')[1:-1]\n",
        "    # text = ' '.join(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "translator = Translator(en_tokenizer, fr_tokenizer, transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEn798B77cRY",
        "outputId": "e22830d5-ecf3-430b-c8ef-5933c4c14d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:         : PREMIÈRE PARTIE\n",
            "Prediction     : start first part\n",
            "Ground truth   : First Part\n"
          ]
        }
      ],
      "source": [
        "sentence = 'PREMIÈRE PARTIE'\n",
        "ground_truth = 'First Part'\n",
        "\n",
        "# sentence = 'Le grand Meaulnes'\n",
        "# ground_truth = 'The Wanderer'\n",
        "\n",
        "# sentence = 'Alain-Fournier'\n",
        "# ground_truth = 'Alain-Fournier'\n",
        "\n",
        "# Tokenize the sentences using the tokenizers\n",
        "encoded_sentence = tf.keras.preprocessing.sequence.pad_sequences(fr_tokenizer.texts_to_sequences([sentence]), padding='post')\n",
        "encoded_ground_truth = tf.keras.preprocessing.sequence.pad_sequences(en_tokenizer.texts_to_sequences([ground_truth]), padding='post')\n",
        "\n",
        "# Print the encoded sequences\n",
        "# print(\"Encoded Sentence:\")\n",
        "# print(encoded_sentence)\n",
        "# print(\"\\nEncoded Ground Truth:\")\n",
        "# print(encoded_ground_truth)\n",
        "\n",
        "translated_text = translator(encoded_sentence, max_length=2)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m56DS55Yysvh"
      },
      "source": [
        "> Examples in French:\n",
        "\n",
        "    Le grand Meaulnes\n",
        "    Alain-Fournier\n",
        "    PREMIÈRE PARTIE\n",
        "\n",
        "> Examples in English:\n",
        "\n",
        "    The Wanderer\n",
        "    Alain-Fournier\n",
        "    First Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLKNDTXeobfb"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAXW3hxG_not",
        "outputId": "9f93bd0a-5d8b-4191-b790-73f5bb511629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score: 0.11428571428571427\n"
          ]
        }
      ],
      "source": [
        "references_list = [['are', 'you', 'fond', 'of', 'and', 'he', 'searched',\n",
        "   'my', 'face', 'with', 'eyes', 'that', 'i', 'saw', 'were',\n",
        "     'dark,', 'and', 'end']]\n",
        "\n",
        "hypothesis = ['start', 'they', 'were', 'waiting', 'for', 'a', 'disposition',\n",
        "               'of', 'the', 'house;', 'and', 'one', 'hand', 'passed', 'her',\n",
        "                 'windows', 'in', 'the', 'did', 'not', 'dwell', 'on', 'the', \n",
        "                 'should', 'quit', 'garden', 'gardiner,', 'whose', 'bright', \n",
        "                 'church', 'bright', '.', '.', \".'\", 'end']\n",
        "\n",
        "# # Reference and hypothesis sentences\n",
        "# references_list = [['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'for']]\n",
        "# hypothesis = ['the', 'fast', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'the', 'lazy', 'dog']\n",
        "\n",
        "# Compute BLEU score for a single sentence\n",
        "bleu_score = corpus_bleu([references_list], [hypothesis], weights=(1, 0, 0, 0))\n",
        "print(f'BLEU Score: {bleu_score}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGLLNwFSASpF",
        "outputId": "1b9ddc1b-710a-4546-91ee-632f91d596fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU Score: 9.418382295637229e-232\n"
          ]
        }
      ],
      "source": [
        "# Reference and hypothesis sentences for multiple examples\n",
        "# DOES NOT WORK\n",
        "references = [\n",
        "    ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'],\n",
        "    ['the', 'cat', 'in', 'the', 'hat']\n",
        "]\n",
        "\n",
        "hypotheses = [\n",
        "    ['the', 'fast', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'],\n",
        "    ['a', 'cat', 'in', 'a', 'hat']\n",
        "]\n",
        "\n",
        "# Compute BLEU score for multiple sentences\n",
        "bleu_score = corpus_bleu(references, hypotheses)\n",
        "print(f'BLEU Score: {bleu_score}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of bleu score on train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating BLEU Score:   0%|          | 0/313 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9230769230769231\n",
            "0.8782051282051282\n",
            "0.891025641025641\n",
            "0.8932692307692307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating BLEU Score:   0%|          | 0/313 [00:07<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27654/2723064678.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Bleu Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moverall_bleu_score\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moverall_bleu_score\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLEU Score on train Dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_27654/2723064678.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(translator, train_dataset, max_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_label_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# ground_truth = ground_truth.split(' ')[1:-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# ground_truth = ' '.join(ground_truth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtranslated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Bleu score evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_27654/1069019772.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sentence, max_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1, X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# Select the last token from the `seq_len` dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Shape `(batch_size, 1, vocab_size)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/1318012798.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, context_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Final linear layer output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/3740988789.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/2507684716.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal_self_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Cache the last attention scores for plotting later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/3341623779.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     attn_output, attn_scores = self.mha(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         value=context)\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/1177736794.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, query, key, value, use_causal_mask)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mconcat_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   5312\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5313\u001b[0m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5314\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   5315\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 5316\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5318\u001b[0m       if (ab_matmul.get_shape().is_fully_defined() and\n\u001b[1;32m   5319\u001b[0m           ab_matmul.get_shape().as_list() == a_free_dims + b_free_dims):\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3838\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjoint_b\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3839\u001b[0m         return gen_math_ops.batch_mat_mul_v3(\n\u001b[1;32m   3840\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3841\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3842\u001b[0;31m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3843\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6173\u001b[0m         transpose_b)\n\u001b[1;32m   6174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6176\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6177\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6178\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6180\u001b[0m       return mat_mul_eager_fallback(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "# Disable specific warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "def calculate_bleu_score(translator, train_dataset, max_length=206):\n",
        "    overall_bleu_score = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    pbar = tqdm(train_dataset, desc=\"Calculating BLEU Score\")\n",
        "\n",
        "    for (fr, en), en_label in pbar:\n",
        "        for i in range(fr.shape[0]):\n",
        "            fr_sentence = fr[i:i+1, :]\n",
        "            en_label_sentence = en_label[i:i+1, :]\n",
        "            ground_truth = en_tokenizer.sequences_to_texts(en_label_sentence.numpy())[0]\n",
        "            # ground_truth = ground_truth.split(' ')[1:-1]\n",
        "            # ground_truth = ' '.join(ground_truth)\n",
        "            \n",
        "            translated_text = translator(fr_sentence, max_length)\n",
        "            \n",
        "            # Bleu score evaluation\n",
        "            references = []\n",
        "            references.append(ground_truth.split(' '))\n",
        "            translated_text = translated_text.split(' ')\n",
        "            overall_bleu_score += corpus_bleu([references], [translated_text], weights=(1, 0, 0, 0))\n",
        "            count += 1\n",
        "\n",
        "        # Display progress in tqdm\n",
        "        pbar.set_postfix({'Bleu Score': overall_bleu_score/count})\n",
        "\n",
        "    return overall_bleu_score/count\n",
        "\n",
        "bleu_score = calculate_bleu_score(translator, train_dataset)\n",
        "print(\"BLEU Score on train Dataset:\", bleu_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation of bleu score on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P9BTZYABlfo",
        "outputId": "09bc20ad-ace6-42be-fe13-9ec02e134715"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating BLEU Score:   3%|▎         | 3/94 [07:25<3:45:26, 148.65s/it, Bleu Score=0.192]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27654/2625688151.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Bleu Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moverall_bleu_score\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moverall_bleu_score\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLEU Score on Test Dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_27654/2625688151.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(translator, test_dataset, max_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_label_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# ground_truth = ground_truth.split(' ')[1:-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# ground_truth = ' '.join(ground_truth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtranslated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Bleu score evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_27654/1069019772.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sentence, max_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1, X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m# Select the last token from the `seq_len` dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Shape `(batch_size, 1, vocab_size)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/1318012798.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, context_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Final linear layer output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/3740988789.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/2507684716.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal_self_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Cache the last attention scores for plotting later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attn_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/3341623779.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     attn_output, attn_scores = self.mha(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         value=context)\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_27654/1177736794.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, query, key, value, use_causal_mask)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mconcat_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_27654/1177736794.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmatmul_qk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mscaled_attention_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_qk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masked_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1152\u001b[0m           \u001b[0mpacked_strides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_strides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m     return strided_slice(\n\u001b[0m\u001b[1;32m   1157\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0mpacked_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[1;32m   1330\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/trans/lib/python3.11/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10934\u001b[0m         \"new_axis_mask\", new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[1;32m  10935\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10936\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10937\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10938\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10939\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10940\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10941\u001b[0m       return strided_slice_eager_fallback(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "# Disable specific warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "def calculate_bleu_score(translator, test_dataset, max_length=206):\n",
        "    overall_bleu_score = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    pbar = tqdm(test_dataset, desc=\"Calculating BLEU Score\")\n",
        "\n",
        "    for (fr, en), en_label in pbar:\n",
        "        for i in range(fr.shape[0]):\n",
        "            fr_sentence = fr[i:i+1, :]\n",
        "            en_label_sentence = en_label[i:i+1, :]\n",
        "            ground_truth = en_tokenizer.sequences_to_texts(en_label_sentence.numpy())[0]\n",
        "            # ground_truth = ground_truth.split(' ')[1:-1]\n",
        "            # ground_truth = ' '.join(ground_truth)\n",
        "            \n",
        "            translated_text = translator(fr_sentence, max_length)\n",
        "            \n",
        "            # Bleu score evaluation\n",
        "            references = []\n",
        "            references.append(ground_truth.split(' '))\n",
        "            translated_text = translated_text.split(' ')\n",
        "            overall_bleu_score += corpus_bleu([references], [translated_text], weights=(1, 0, 0, 0))\n",
        "            count += 1\n",
        "\n",
        "        # Display progress in tqdm\n",
        "        pbar.set_postfix({'Bleu Score': overall_bleu_score/count})\n",
        "\n",
        "    return overall_bleu_score/count\n",
        "\n",
        "bleu_score = calculate_bleu_score(translator, test_dataset)\n",
        "print(\"BLEU Score on Test Dataset:\", bleu_score)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fe060f155f94172aa9dfb56d84a32a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12f5d21a55084a1eb82fc10a630f511f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14990ee7be254c2fbb1a99a8f3239d83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1504f8fe687e4fecaf7134fc41f5cbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c258bf997cb042c6b275f84c01b355d6",
            "placeholder": "​",
            "style": "IPY_MODEL_5a2c40b518f4482d8a81be32de548850",
            "value": " 21.0M/21.0M [00:01&lt;00:00, 23.3MB/s]"
          }
        },
        "170308f08d8d41f8953bdfea1b0186bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5cac31d8d3e4de782cea6967aaf9413",
            "placeholder": "​",
            "style": "IPY_MODEL_9c1bb89cd526494891b09755281d76ef",
            "value": " 126125/? [00:23&lt;00:00, 5368.88 examples/s]"
          }
        },
        "176617868e13453393f6e25220450130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_261b676b5c3947d8be328322f29fc34b",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe060f155f94172aa9dfb56d84a32a7",
            "value": "Generating train split: 100%"
          }
        },
        "1e2fa0ff8d9742508d05c9910654551e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1c05936d6374066bab9be98bd0adbe8",
              "IPY_MODEL_551851c669c84fe09c82dd98bc6dbf01",
              "IPY_MODEL_1504f8fe687e4fecaf7134fc41f5cbbb"
            ],
            "layout": "IPY_MODEL_c432ca86db394831a06381ba5131a154"
          }
        },
        "2349d26748a443f7956c1c614b732544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9586d1c2a9a34baea77dd043ac9a0409",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4a6ef913325496385c81f87676de5b3",
            "value": 1
          }
        },
        "24d5a44a8169446183dfed66fa2a5e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_406fa15cd71f43f8b22f0edc2e6751ab",
            "max": 127085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72f22ff4856f4bbcabd60dfe4e7af8d9",
            "value": 127085
          }
        },
        "261b676b5c3947d8be328322f29fc34b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a9d177f540445396617d6e4dee290e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2917f9ef0bc84fd8b1889ed3f7d2ca5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3392047892054d5893b3c6f5fd44c8de",
              "IPY_MODEL_2349d26748a443f7956c1c614b732544",
              "IPY_MODEL_75b7730f4ced4d9d8ce696b2e494fddc"
            ],
            "layout": "IPY_MODEL_911b832e2351425f9bc7acc6dc04c4fe"
          }
        },
        "2ecb77fbda9149e886040a4a4b71f15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310248f70a844312af4b01d8bf989910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47935958a0c64d7aa9720bdf5730c52d",
            "placeholder": "​",
            "style": "IPY_MODEL_c28ab0a4cb7846fea2e64f9cd19bd906",
            "value": " 126720/127085 [00:00&lt;00:00, 442362.87 examples/s]"
          }
        },
        "3392047892054d5893b3c6f5fd44c8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a9d177f540445396617d6e4dee290e",
            "placeholder": "​",
            "style": "IPY_MODEL_561ab8a97577469c8932ca86cd4f157b",
            "value": "Generating splits...: 100%"
          }
        },
        "33e76f7907b64cc8a9dba236b94330bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36cf659c026f4a949422af3738711f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97cc923d5cff4892a25e6c85d2379dd8",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a5e30d376340c1b529bec2eced3aef",
            "value": "Generating train examples...: "
          }
        },
        "39fea0018eaa4110b2ab96d300e9f7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a60f76da394994b50af9b81c3f2834",
            "max": 127085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c6be6fd17a64322a6a3d28bb547de13",
            "value": 127085
          }
        },
        "406fa15cd71f43f8b22f0edc2e6751ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4596c827b1c54c6db71547a2349a0189": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36cf659c026f4a949422af3738711f0c",
              "IPY_MODEL_bf9d5ba948a24acd8b6a3f6961969807",
              "IPY_MODEL_170308f08d8d41f8953bdfea1b0186bd"
            ],
            "layout": "IPY_MODEL_d187481bbd584dba8d868dc95299a7aa"
          }
        },
        "46a60f76da394994b50af9b81c3f2834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47935958a0c64d7aa9720bdf5730c52d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb221bf6a5f4f3f8768f9de79a31513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc3898089d7d437d9cca75c43ae0e36f",
            "placeholder": "​",
            "style": "IPY_MODEL_baaf6373c2f34eb1983dc5dcb4a03728",
            "value": " 127085/127085 [00:00&lt;00:00, 390918.48 examples/s]"
          }
        },
        "551851c669c84fe09c82dd98bc6dbf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a2e7b63ecc44c989d9eea886f1d612",
            "max": 20985324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2ee4bad6ad3404bb18c75d20003ed37",
            "value": 20985324
          }
        },
        "561ab8a97577469c8932ca86cd4f157b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b1c227edfc4ea2b8b4ecf27a355e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_176617868e13453393f6e25220450130",
              "IPY_MODEL_39fea0018eaa4110b2ab96d300e9f7d4",
              "IPY_MODEL_4fb221bf6a5f4f3f8768f9de79a31513"
            ],
            "layout": "IPY_MODEL_33e76f7907b64cc8a9dba236b94330bf"
          }
        },
        "5a2c40b518f4482d8a81be32de548850": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a2e7b63ecc44c989d9eea886f1d612": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f22ff4856f4bbcabd60dfe4e7af8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72fb6934a8b34071a737256b0c751ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75b7730f4ced4d9d8ce696b2e494fddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f5d21a55084a1eb82fc10a630f511f",
            "placeholder": "​",
            "style": "IPY_MODEL_2ecb77fbda9149e886040a4a4b71f15c",
            "value": " 1/1 [00:24&lt;00:00, 24.50s/ splits]"
          }
        },
        "7c6be6fd17a64322a6a3d28bb547de13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911b832e2351425f9bc7acc6dc04c4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9586d1c2a9a34baea77dd043ac9a0409": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d512ae32164dd3a0014a1ff850b3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "97cc923d5cff4892a25e6c85d2379dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c1bb89cd526494891b09755281d76ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fb1066f2ade48efa6f1937760c54eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1c05936d6374066bab9be98bd0adbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c83302272e864d1dabf1309588bbd3de",
            "placeholder": "​",
            "style": "IPY_MODEL_fb81c4ea319449c494eab9a5bb82adaa",
            "value": "Downloading data: 100%"
          }
        },
        "ab4ccf5bbaea48b2bcac1475a2e9f3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be1202359bb849d8a9a1ded79213c94e",
              "IPY_MODEL_24d5a44a8169446183dfed66fa2a5e34",
              "IPY_MODEL_310248f70a844312af4b01d8bf989910"
            ],
            "layout": "IPY_MODEL_e2bee257450a46eb9b2775142bc5d073"
          }
        },
        "baaf6373c2f34eb1983dc5dcb4a03728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc3898089d7d437d9cca75c43ae0e36f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1202359bb849d8a9a1ded79213c94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14990ee7be254c2fbb1a99a8f3239d83",
            "placeholder": "​",
            "style": "IPY_MODEL_9fb1066f2ade48efa6f1937760c54eba",
            "value": "Shuffling /root/tensorflow_datasets/opus_books/en-fr/1.0.0.incompleteKC2F9K/opus_books-train.tfrecord*...: 100%"
          }
        },
        "bf9d5ba948a24acd8b6a3f6961969807": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d512ae32164dd3a0014a1ff850b3f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72fb6934a8b34071a737256b0c751ade",
            "value": 1
          }
        },
        "c258bf997cb042c6b275f84c01b355d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28ab0a4cb7846fea2e64f9cd19bd906": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c432ca86db394831a06381ba5131a154": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cac31d8d3e4de782cea6967aaf9413": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83302272e864d1dabf1309588bbd3de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d187481bbd584dba8d868dc95299a7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d2ee4bad6ad3404bb18c75d20003ed37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2bee257450a46eb9b2775142bc5d073": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e4a6ef913325496385c81f87676de5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a5e30d376340c1b529bec2eced3aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb81c4ea319449c494eab9a5bb82adaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
